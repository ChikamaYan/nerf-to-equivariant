{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37864bitnerfconda1ad5715b4c6e4a6bbbec978bd1f18994",
   "display_name": "Python 3.7.8 64-bit ('nerf': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import imageio\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "from run_nerf_helpers import *\n",
    "from load_llff import load_llff_data\n",
    "from load_deepvoxels import load_dv_data\n",
    "from load_blender import load_blender_data\n",
    "tf.compat.v1.enable_eager_execution()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def config_parser():\n",
    "\n",
    "    import configargparse\n",
    "    parser = configargparse.ArgumentParser()\n",
    "    parser.add_argument('--config', is_config_file=True,\n",
    "                        help='config file path')\n",
    "    parser.add_argument(\"--expname\", type=str, help='experiment name')\n",
    "    parser.add_argument(\"--basedir\", type=str, default='./logs/',\n",
    "                        help='where to store ckpts and logs')\n",
    "    parser.add_argument(\"--datadir\", type=str,\n",
    "                        default='./data/llff/fern', help='input data directory')\n",
    "\n",
    "    # training options\n",
    "    parser.add_argument(\"--netdepth\", type=int, default=8,\n",
    "                        help='layers in network')\n",
    "    parser.add_argument(\"--netwidth\", type=int, default=256,\n",
    "                        help='channels per layer')\n",
    "    parser.add_argument(\"--netdepth_fine\", type=int,\n",
    "                        default=8, help='layers in fine network')\n",
    "    parser.add_argument(\"--netwidth_fine\", type=int, default=256,\n",
    "                        help='channels per layer in fine network')\n",
    "    parser.add_argument(\"--N_rand\", type=int, default=32*32*4,\n",
    "                        help='batch size (number of random rays per gradient step)')\n",
    "    parser.add_argument(\"--lrate\", type=float,\n",
    "                        default=5e-4, help='learning rate')\n",
    "    parser.add_argument(\"--lrate_decay\", type=int, default=250,\n",
    "                        help='exponential learning rate decay (in 1000s)')\n",
    "    parser.add_argument(\"--chunk\", type=int, default=1024*32,\n",
    "                        help='number of rays processed in parallel, decrease if running out of memory')\n",
    "    parser.add_argument(\"--netchunk\", type=int, default=1024*64,\n",
    "                        help='number of pts sent through network in parallel, decrease if running out of memory')\n",
    "    parser.add_argument(\"--no_batching\", action='store_true',\n",
    "                        help='only take random rays from 1 image at a time')\n",
    "    parser.add_argument(\"--no_reload\", action='store_true',\n",
    "                        help='do not reload weights from saved ckpt')\n",
    "    parser.add_argument(\"--ft_path\", type=str, default=None,\n",
    "                        help='specific weights npy file to reload for coarse network')\n",
    "    parser.add_argument(\"--random_seed\", type=int, default=None,\n",
    "                        help='fix random seed for repeatability')\n",
    "    \n",
    "    # pre-crop options\n",
    "    parser.add_argument(\"--precrop_iters\", type=int, default=0,\n",
    "                        help='number of steps to train on central crops')\n",
    "    parser.add_argument(\"--precrop_frac\", type=float,\n",
    "                        default=.5, help='fraction of img taken for central crops')    \n",
    "\n",
    "    # rendering options\n",
    "    parser.add_argument(\"--N_samples\", type=int, default=64,\n",
    "                        help='number of coarse samples per ray')\n",
    "    parser.add_argument(\"--N_importance\", type=int, default=0,\n",
    "                        help='number of additional fine samples per ray')\n",
    "    parser.add_argument(\"--perturb\", type=float, default=1.,\n",
    "                        help='set to 0. for no jitter, 1. for jitter')\n",
    "    parser.add_argument(\"--use_viewdirs\", action='store_true',\n",
    "                        help='use full 5D input instead of 3D')\n",
    "    parser.add_argument(\"--i_embed\", type=int, default=0,\n",
    "                        help='set 0 for default positional encoding, -1 for none')\n",
    "    parser.add_argument(\"--multires\", type=int, default=10,\n",
    "                        help='log2 of max freq for positional encoding (3D location)')\n",
    "    parser.add_argument(\"--multires_views\", type=int, default=4,\n",
    "                        help='log2 of max freq for positional encoding (2D direction)')\n",
    "    parser.add_argument(\"--raw_noise_std\", type=float, default=0.,\n",
    "                        help='std dev of noise added to regularize sigma_a output, 1e0 recommended')\n",
    "\n",
    "    parser.add_argument(\"--render_only\", action='store_true',\n",
    "                        help='do not optimize, reload weights and render out render_poses path')\n",
    "    parser.add_argument(\"--render_test\", action='store_true',\n",
    "                        help='render the test set instead of render_poses path')\n",
    "    parser.add_argument(\"--render_factor\", type=int, default=0,\n",
    "                        help='downsampling factor to speed up rendering, set 4 or 8 for fast preview')\n",
    "\n",
    "    # dataset options\n",
    "    parser.add_argument(\"--dataset_type\", type=str, default='llff',\n",
    "                        help='options: llff / blender / deepvoxels')\n",
    "    parser.add_argument(\"--testskip\", type=int, default=8,\n",
    "                        help='will load 1/N images from test/val sets, useful for large datasets like deepvoxels')\n",
    "\n",
    "    # deepvoxels flags\n",
    "    parser.add_argument(\"--shape\", type=str, default='greek',\n",
    "                        help='options : armchair / cube / greek / vase')\n",
    "\n",
    "    # blender flags\n",
    "    parser.add_argument(\"--white_bkgd\", action='store_true',\n",
    "                        help='set to render synthetic data on a white bkgd (always use for dvoxels)')\n",
    "    parser.add_argument(\"--half_res\", action='store_true',\n",
    "                        help='load blender synthetic data at 400x400 instead of 800x800')\n",
    "\n",
    "    # llff flags\n",
    "    parser.add_argument(\"--factor\", type=int, default=8,\n",
    "                        help='downsample factor for LLFF images')\n",
    "    parser.add_argument(\"--no_ndc\", action='store_true',\n",
    "                        help='do not use normalized device coordinates (set for non-forward facing scenes)')\n",
    "    parser.add_argument(\"--lindisp\", action='store_true',\n",
    "                        help='sampling linearly in disparity rather than depth')\n",
    "    parser.add_argument(\"--spherify\", action='store_true',\n",
    "                        help='set for spherical 360 scenes')\n",
    "    parser.add_argument(\"--llffhold\", type=int, default=8,\n",
    "                        help='will take every 1/N images as LLFF test set, paper uses 8')\n",
    "\n",
    "    # logging/saving options\n",
    "    parser.add_argument(\"--i_print\",   type=int, default=100,\n",
    "                        help='frequency of console printout and metric loggin')\n",
    "    parser.add_argument(\"--i_img\",     type=int, default=500,\n",
    "                        help='frequency of tensorboard image logging')\n",
    "    parser.add_argument(\"--i_weights\", type=int, default=10000,\n",
    "                        help='frequency of weight ckpt saving')\n",
    "    parser.add_argument(\"--i_testset\", type=int, default=50000,\n",
    "                        help='frequency of testset saving')\n",
    "    parser.add_argument(\"--i_video\",   type=int, default=50000,\n",
    "                        help='frequency of render_poses video saving')\n",
    "\n",
    "    # rotation equivariant option\n",
    "    parser.add_argument(\"--use_rotation\",action='store_true',\n",
    "                        help='use rotation equivariant for training')\n",
    "\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From /cs/student/projects1/2019/tianhawu/nerf-to-equivariant/load_blender.py:82: The name tf.image.resize_area is deprecated. Please use tf.compat.v1.image.resize_area instead.\n\nLoaded blender (138, 400, 400, 4) (40, 4, 4) [400, 400, 555.5555155968841] ./data/nerf_synthetic/lego\n"
    }
   ],
   "source": [
    "parser = config_parser()\n",
    "args = parser.parse_args(\"--config config_lego_rotation.txt\")\n",
    "\n",
    "if args.random_seed is not None:\n",
    "    print('Fixing random seed', args.random_seed)\n",
    "    np.random.seed(args.random_seed)\n",
    "    tf.compat.v1.set_random_seed(args.random_seed)\n",
    "\n",
    "# lego dataset is blender type + white background\n",
    "\n",
    "if args.dataset_type == 'blender':\n",
    "    # this pose here only takes transformation matrix, not rotation\n",
    "    images, poses, render_poses, hwf, i_split = load_blender_data(\n",
    "        args.datadir, args.half_res, args.testskip)\n",
    "    print('Loaded blender', images.shape,\n",
    "            render_poses.shape, hwf, args.datadir)\n",
    "    i_train, i_val, i_test = i_split\n",
    "\n",
    "    near = 2.\n",
    "    far = 6.\n",
    "\n",
    "    if args.white_bkgd:\n",
    "        images = images[..., :3]*images[..., -1:] + (1.-images[..., -1:])\n",
    "    else:\n",
    "        images = images[..., :3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[[-9.9990219e-01,  4.1922452e-03, -1.3345719e-02, -5.3798322e-02],\n        [-1.3988681e-02, -2.9965907e-01,  9.5394367e-01,  3.8454704e+00],\n        [-4.6566129e-10,  9.5403719e-01,  2.9968831e-01,  1.2080823e+00],\n        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.0000000e+00]],\n\n       [[-9.3054223e-01,  1.1707554e-01, -3.4696460e-01, -1.3986591e+00],\n        [-3.6618456e-01, -2.9751042e-01,  8.8170075e-01,  3.5542498e+00],\n        [ 7.4505806e-09,  9.4751304e-01,  3.1971723e-01,  1.2888215e+00],\n        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.0000000e+00]],\n\n       [[ 4.4296363e-01,  3.1377721e-01, -8.3983749e-01, -3.3854935e+00],\n        [-8.9653969e-01,  1.5503149e-01, -4.1494811e-01, -1.6727095e+00],\n        [ 0.0000000e+00,  9.3675458e-01,  3.4998694e-01,  1.4108427e+00],\n        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.0000000e+00]],\n\n       ...,\n\n       [[-6.2794067e-02, -6.5946466e-01,  7.4910831e-01,  3.0197523e+00],\n        [ 9.9802655e-01, -4.1492354e-02,  4.7132574e-02,  1.8999748e-01],\n        [ 0.0000000e+00,  7.5058967e-01,  6.6076863e-01,  2.6636436e+00],\n        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.0000000e+00]],\n\n       [[-5.3582996e-01, -5.9115911e-01,  6.0284096e-01,  2.4301295e+00],\n        [ 8.4432590e-01, -3.7516409e-01,  3.8257766e-01,  1.5422199e+00],\n        [ 1.4901159e-08,  7.1399069e-01,  7.0015514e-01,  2.8224156e+00],\n        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.0000000e+00]],\n\n       [[-8.7630844e-01, -3.4907752e-01,  3.3200625e-01,  1.3383600e+00],\n        [ 4.8175019e-01, -6.3497555e-01,  6.0392272e-01,  2.4344904e+00],\n        [ 0.0000000e+00,  6.8916672e-01,  7.2460276e-01,  2.9209671e+00],\n        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.0000000e+00]]],\n      dtype=float32)"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}